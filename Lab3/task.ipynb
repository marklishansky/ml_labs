{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Пример импорта данных. Грузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# загрузка данных\n",
    "path_to_dataset = '/Users/daniil/nn_ml_practice/insurance.csv'\n",
    "data = pd.read_csv(path_to_dataset, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии (если у вас многоклассовая классификация, прочтите P.S.S. внизу)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моя задача относится к регрессии, так как я пытаюсь предсказать медицинские расходы, которые представлены в виде непрерывных числовых значений и они не принимают дискретные значения, представляющие категории или классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Сделать предобработку данных:\n",
    "Разделить выборку на тренировочную (train) и тестовую (test). Обратите внимание, что обучать скейлеры и определять, какими значениями вы будете заполнять пропуски, вы будете на train выборке, а применять и на train, и на test.\n",
    "Проверить пропуски в данных. Если они есть, заполнить одной из стратегий, предложенных в ноутбуке для семинара №3. P.S. Для численных и категориальных переменных будут разные стратегии.\n",
    "Отнормировать численные переменные (StandardScaler, MinMaxScaler).\n",
    "Закодировать категориальные признаки по одной из стратегий.\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "(1070, 11)\n",
      "(268, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "path_to_dataset = '/Users/daniil/nn_ml_practice/insurance.csv'\n",
    "data = pd.read_csv(path_to_dataset, sep=',')\n",
    "\n",
    "# проверка на наличие пропусков\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# разделение данных на признаки и целевую переменную\n",
    "X = data.drop('charges', axis=1)\n",
    "y = data['charges']\n",
    "\n",
    "# разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# определение числовых и категориальных признаков\n",
    "numeric_features = ['age', 'bmi', 'children']\n",
    "categorical_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "# пайплайн для числовых признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Заполнение пропусков средним значением\n",
    "    ('scaler', StandardScaler())  # Нормализация StandardScaler\n",
    "])\n",
    "\n",
    "# пайплайн для категориальных признаков\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # заполнение пропусков наиболее частым значением\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # OneHotEncoder для кодирования категориальных признаков\n",
    "])\n",
    "\n",
    "# комбинирование пайплайнов с помощью ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# применение преобразований к тренировочным и тестовым данным\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# проверка результирующих массивов\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По выводу понятно, что пропусков у нас нет, заполнять их не нужно.\n",
    "Тренировочная выборка содержит 1070 строк и 11 столбцов.\n",
    "Тестовая выборка содержит 268 строк и 11 столбцов.\n",
    "Мы нормализовали числовые переменные и закодировали категориальные признаки с помощью ColumnTransformer и Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучить на тренировочном множестве:\n",
    "Линейную модель (LogisticRegression, LinearRegression)\n",
    "Деревянную модель (DecisionTreeClassifier, DecisionTreeRegressor) (тут советую попробовать разные глубины деревьев)\n",
    "K-ближайших соседей (KNeighborsClassifier, KNeighborsRegressor) (тут тоже есть смысл попробовать разные k)\n",
    "Случайный лес (RandomForestClassifier, RandomForestRegressor)\n",
    "\n",
    "Мы рассмотрим следующие модели:\n",
    "\n",
    "Линейная регрессия (LinearRegression)\n",
    "Дерево решений для регрессии (DecisionTreeRegressor)\n",
    "K-ближайших соседей для регрессии (KNeighborsRegressor)\n",
    "Случайный лес для регрессии (RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "Linear Regression - MSE: 33596915.851361476, R^2: 0.7835929767120722\n",
      "Decision Tree (max_depth=5) - MSE: 25857792.05855163, R^2: 0.8334428126395235\n",
      "K-Neighbors (k=5) - MSE: 35984256.904628225, R^2: 0.7682154529775659\n",
      "Random Forest (max_depth=5) - MSE: 19743528.653210577, R^2: 0.8728264735982286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "path_to_dataset = '/Users/daniil/nn_ml_practice/insurance.csv'\n",
    "data = pd.read_csv(path_to_dataset, sep=',')\n",
    "\n",
    "# проверка пропусков\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop(columns='charges')\n",
    "y = data['charges']\n",
    "\n",
    "# разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# определение числовых и категориальных признаков\n",
    "numeric_features = ['age', 'bmi', 'children']\n",
    "categorical_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "# создание трансформеров для числовых и категориальных признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# объединение трансформеров в единый препроцессор\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# обучение линейной регрессии\n",
    "lin_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin_reg = lin_reg.predict(X_test)\n",
    "\n",
    "# обучение дерева решений для регрессии\n",
    "tree_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=5))\n",
    "])\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_pred_tree_reg = tree_reg.predict(X_test)\n",
    "\n",
    "# обучение K-ближайших соседей для регрессии\n",
    "knn_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_reg.fit(X_train, y_train)\n",
    "y_pred_knn_reg = knn_reg.predict(X_test)\n",
    "\n",
    "# обучение случайного леса для регрессии\n",
    "forest_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "forest_reg.fit(X_train, y_train)\n",
    "y_pred_forest_reg = forest_reg.predict(X_test)\n",
    "\n",
    "# оценка моделей\n",
    "models = {\n",
    "    \"Linear Regression\": (y_pred_lin_reg, lin_reg),\n",
    "    \"Decision Tree (max_depth=5)\": (y_pred_tree_reg, tree_reg),\n",
    "    \"K-Neighbors (k=5)\": (y_pred_knn_reg, knn_reg),\n",
    "    \"Random Forest (max_depth=5)\": (y_pred_forest_reg, forest_reg)\n",
    "}\n",
    "\n",
    "for model_name, (y_pred, model) in models.items():\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse}, R^2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Посчитайте метрики на train и test множествах:\n",
    "Для задачи классификации -- Accuracy, ROC-AUC (график + значение), PR-кривую (график), F1-score\n",
    "Для задачи регрессии -- MAE, RMSE, MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "Linear Regression - Train MAE: 4208.234572492226, Train RMSE: 6105.545160099848, Train MAPE: 42.20268508031658\n",
      "Linear Regression - Test MAE: 4181.194473753652, Test RMSE: 5796.284659276274, Test MAPE: 46.88825597914694\n",
      "Decision Tree (max_depth=5) - Train MAE: 2323.7044277482587, Train RMSE: 4142.694257687975, Train MAPE: 27.961164929868204\n",
      "Decision Tree (max_depth=5) - Test MAE: 2911.1600498786056, Test RMSE: 5085.055757663983, Test MAPE: 34.55446483446007\n",
      "K-Neighbors (k=5) - Train MAE: 2859.823881779439, Train RMSE: 4773.829774933797, Train MAPE: 29.21651246242549\n",
      "K-Neighbors (k=5) - Test MAE: 3631.59117925, Test RMSE: 5998.687931925466, Test MAPE: 40.29677995026158\n",
      "Random Forest (max_depth=5) - Train MAE: 2254.839625100894, Train RMSE: 4043.7311642356385, Train MAPE: 27.31552161757523\n",
      "Random Forest (max_depth=5) - Test MAE: 2558.6914480028695, Test RMSE: 4443.369065608953, Test MAPE: 31.468820045340827\n"
     ]
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "ath_to_dataset = '/Users/daniil/nn_ml_practice/insurance.csv'\n",
    "data = pd.read_csv(path_to_dataset, sep=',')\n",
    "\n",
    "# Проверка пропусков\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop(columns='charges')\n",
    "y = data['charges']\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение числовых и категориальных признаков\n",
    "numeric_features = ['age', 'bmi', 'children']\n",
    "categorical_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "# Создание трансформеров для числовых и категориальных признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединение трансформеров в единый препроцессор\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Функция для вычисления метрик\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mae, rmse, mape\n",
    "\n",
    "# Функция для вывода метрик\n",
    "def print_metrics(model_name, y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    train_mae, train_rmse, train_mape = calculate_metrics(y_train_true, y_train_pred)\n",
    "    test_mae, test_rmse, test_mape = calculate_metrics(y_test_true, y_test_pred)\n",
    "    print(f\"{model_name} - Train MAE: {train_mae}, Train RMSE: {train_rmse}, Train MAPE: {train_mape}\")\n",
    "    print(f\"{model_name} - Test MAE: {test_mae}, Test RMSE: {test_rmse}, Test MAPE: {test_mape}\")\n",
    "\n",
    "# Обучение и оценка линейной регрессии\n",
    "lin_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_train_pred_lin_reg = lin_reg.predict(X_train)\n",
    "y_test_pred_lin_reg = lin_reg.predict(X_test)\n",
    "\n",
    "print_metrics(\"Linear Regression\", y_train, y_train_pred_lin_reg, y_test, y_test_pred_lin_reg)\n",
    "\n",
    "# Обучение и оценка дерева решений для регрессии\n",
    "tree_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=5))\n",
    "])\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_train_pred_tree_reg = tree_reg.predict(X_train)\n",
    "y_test_pred_tree_reg = tree_reg.predict(X_test)\n",
    "\n",
    "print_metrics(\"Decision Tree (max_depth=5)\", y_train, y_train_pred_tree_reg, y_test, y_test_pred_tree_reg)\n",
    "\n",
    "# Обучение и оценка K-ближайших соседей для регрессии\n",
    "knn_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_reg.fit(X_train, y_train)\n",
    "y_train_pred_knn_reg = knn_reg.predict(X_train)\n",
    "y_test_pred_knn_reg = knn_reg.predict(X_test)\n",
    "\n",
    "print_metrics(\"K-Neighbors (k=5)\", y_train, y_train_pred_knn_reg, y_test, y_test_pred_knn_reg)\n",
    "\n",
    "# Обучение и оценка случайного леса для регрессии\n",
    "forest_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "forest_reg.fit(X_train, y_train)\n",
    "y_train_pred_forest_reg = forest_reg.predict(X_train)\n",
    "y_test_pred_forest_reg = forest_reg.predict(X_test)\n",
    "\n",
    "print_metrics(\"Random Forest (max_depth=5)\", y_train, y_train_pred_forest_reg, y_test, y_test_pred_forest_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:\n",
    "Какая модель справилась лучше с поставленной задачей?\n",
    "Имеет ли место переобучение?\n",
    "Имеет ли место недообучение?\n",
    "Как можно улучшить метрики моделей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Какая модель справилась лучше с поставленной задачей?\n",
    "Random Forest (max_depth=5) показала наилучшие результаты среди всех моделей:\n",
    "Train MAE: 2254.84\n",
    "Train RMSE: 4043.73\n",
    "Train MAPE: 27.32\n",
    "Test MAE: 2558.69\n",
    "Test RMSE: 4443.37\n",
    "Test MAPE: 31.47\n",
    "2) Имеет ли место переобучение?\n",
    "Decision Tree (max_depth=5): Есть признаки переобучения, так как ошибка на тестовой выборке (Test MAE: 2911.16, Test RMSE: 5085.06) значительно выше, чем на тренировочной выборке (Train MAE: 2323.70, Train RMSE: 4142.69).\n",
    "\n",
    "K-Neighbors (k=5): Тоже наблюдается переобучение, так как метрики на тестовой выборке (Test MAE: 3631.59, Test RMSE: 5998.69) хуже, чем на тренировочной (Train MAE: 2859.82, Train RMSE: 4773.83).\n",
    "\n",
    "Random Forest (max_depth=5): Переобучение менее выражено, метрики на тестовой выборке не сильно отличаются от метрик на тренировочной.\n",
    "3) Имеет ли место недообучение?\n",
    "Linear Regression: В некоторой степени да, поскольку метрики на тренировочной выборке (Train MAE: 4208.23, Train RMSE: 6105.55) и на тестовой выборке (Test MAE: 4181.19, Test RMSE: 5796.28) достаточно высоки, что указывает на недостаточную модельную сложность для улавливания паттернов в данных.\n",
    "4) Как можно улучшить метрики моделей?\n",
    "- Увеличение сложности моделей (Для дерева решений можно попробовать увеличить глубину дерева, для случайного леса можно увеличить количество деревьев или их глубину, для k-ближайших соседей можно попробовать разные значения k)\n",
    "- Тюнинг гиперпараметров (провести поиск гиперпараметров (например, с использованием GridSearchCV или RandomizedSearchCV) для каждой модели, чтобы найти оптимальные параметры)\n",
    "- Добавление новых признаков (Инженерия признаков может помочь улучшить модель, добавив новые релевантные признаки или преобразования текущих)\n",
    "- Использование ансамблей (Можно попробовать более сложные ансамблевые методы, такие как Gradient Boosting Machines (GBM) или XGBoost)\n",
    "- Улучшение предобработки данных (Проверить и улучшить текущую нормализацию и кодирование признаков)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
